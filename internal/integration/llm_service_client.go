package integration

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"strings"
	"sync"
	"time"
)

// LLMServiceClient LLMæœåŠ¡å®¢æˆ·ç«¯å®ç°
type LLMServiceClient struct {
	config       LLMServiceConfig
	httpClient   *http.Client
	concurrency  ConcurrencyManager
	metrics      MetricsCollector
}

// NewLLMServiceClient åˆ›å»ºLLMæœåŠ¡å®¢æˆ·ç«¯
func NewLLMServiceClient(config LLMServiceConfig) LLMService {
	return &LLMServiceClient{
		config: config,
		httpClient: &http.Client{
			Timeout: config.Timeout,
		},
		// concurrency å’Œ metrics å°†åœ¨ orchestrator ä¸­æ³¨å…¥
	}
}

// SetDependencies è®¾ç½®ä¾èµ–ï¼ˆç”¨äºä¾èµ–æ³¨å…¥ï¼‰
func (c *LLMServiceClient) SetDependencies(concurrency ConcurrencyManager, metrics MetricsCollector) {
	c.concurrency = concurrency
	c.metrics = metrics
}

// CleanDataConcurrently å¹¶å‘æ¸…æ´—æ•°æ®
func (c *LLMServiceClient) CleanDataConcurrently(ctx context.Context, request LLMCleaningRequest) ([]CleanedDataItem, error) {
	startTime := time.Now()
	defer func() {
		c.metrics.RecordProcessingDuration("llm_data_cleaning", time.Since(startTime))
	}()

	// æŒ‰ç¼–ç å‰ç¼€åˆ†ç»„æ•°æ®ï¼ˆ1-8å¤§ç±»ï¼‰
	groups := c.groupPDFDataByPrefix(request.RawData)
	
	if len(groups) == 0 {
		return []CleanedDataItem{}, fmt.Errorf("no data groups found")
	}

	// ä½¿ç”¨é…é¢æ„ŸçŸ¥çš„å¹¶å‘å¤„ç†
	results, err := c.processConcurrentlyWithQuota(ctx, groups, request.TaskType)
	if err != nil {
		c.metrics.RecordError("llm_data_cleaning", err)
		return nil, err
	}

	c.metrics.RecordSuccess("llm_data_cleaning")
	return results, nil
}

// AnalyzeSemanticsConcurrently å¹¶å‘è¯­ä¹‰åˆ†æ
func (c *LLMServiceClient) AnalyzeSemanticsConcurrently(ctx context.Context, request LLMSemanticRequest) ([]FinalResultItem, error) {
	startTime := time.Now()
	defer func() {
		c.metrics.RecordProcessingDuration("llm_semantic_analysis", time.Since(startTime))
	}()

	// ä½¿ç”¨ä»»åŠ¡ç±»å‹è½®è¯¢å®ç°å¹¶å‘ï¼Œé¿å…å•ä¸€é˜Ÿåˆ—ç“¶é¢ˆ
	results, err := c.processSemanticChoicesWithTaskRotation(ctx, request.Choices, request.TaskType)
	if err != nil {
		c.metrics.RecordError("llm_semantic_analysis", err)
		return nil, err
	}

	c.metrics.RecordSuccess("llm_semantic_analysis")
	return results, nil
}

// ProcessSingleTask å¤„ç†å•ä¸ªä»»åŠ¡
func (c *LLMServiceClient) ProcessSingleTask(ctx context.Context, taskType string, prompt string) (string, error) {
	return c.callLLMServiceWithRetry(ctx, taskType, prompt, c.config.MaxRetries)
}

// groupPDFDataByPrefix æŒ‰ç¼–ç å‰ç¼€åˆ†ç»„PDFæ•°æ®
func (c *LLMServiceClient) groupPDFDataByPrefix(rawData []PDFOccupationCode) map[string][]PDFOccupationCode {
	groups := make(map[string][]PDFOccupationCode)

	for _, item := range rawData {
		prefix := c.getMainCategoryPrefix(item.Code)
		groups[prefix] = append(groups[prefix], item)
	}

	return groups
}

// getMainCategoryPrefix è·å–ä¸»åˆ†ç±»å‰ç¼€
func (c *LLMServiceClient) getMainCategoryPrefix(code string) string {
	parts := strings.Split(code, "-")
	if len(parts) > 0 {
		return parts[0]
	}
	if len(code) > 0 {
		return string(code[0])
	}
	return "unknown"
}

// processConcurrentlyWithQuota ä½¿ç”¨é…é¢æ„ŸçŸ¥çš„å¹¶å‘å¤„ç†
func (c *LLMServiceClient) processConcurrentlyWithQuota(ctx context.Context, groups map[string][]PDFOccupationCode, taskType string) ([]CleanedDataItem, error) {
	type groupResult struct {
		prefix string
		items  []CleanedDataItem
		err    error
	}

	resultCh := make(chan groupResult, len(groups))
	var wg sync.WaitGroup

	// ä¸ºæ¯ä¸ªåˆ†ç»„å¯åŠ¨goroutineï¼Œä½¿ç”¨é…é¢ç®¡ç†å™¨æ§åˆ¶å¹¶å‘
	for prefix, groupData := range groups {
		wg.Add(1)
		go func(prefix string, data []PDFOccupationCode) {
			defer wg.Done()

			// è·å–å¹¶å‘è®¸å¯
			if err := c.concurrency.AcquirePermit(ctx, taskType); err != nil {
				resultCh <- groupResult{prefix: prefix, err: err}
				return
			}
			defer c.concurrency.ReleasePermit(taskType)

			// å¤„ç†å•ä¸ªåˆ†ç»„
			items, err := c.processSingleGroup(ctx, prefix, data, taskType)
			resultCh <- groupResult{
				prefix: prefix,
				items:  items,
				err:    err,
			}

			// æ›´æ–°æŒ‡æ ‡
			c.concurrency.UpdateMetrics(taskType, TaskMetrics{
				Duration: time.Since(time.Now()),
				Success:  err == nil,
				ErrorType: func() string {
					if err != nil {
						return err.Error()
					}
					return ""
				}(),
			})
		}(prefix, groupData)
	}

	// ç­‰å¾…æ‰€æœ‰goroutineå®Œæˆ
	go func() {
		wg.Wait()
		close(resultCh)
	}()

	// æ”¶é›†ç»“æœ
	var allResults []CleanedDataItem
	var errors []error

	for result := range resultCh {
		if result.err != nil {
			errors = append(errors, fmt.Errorf("group %s failed: %w", result.prefix, result.err))
		} else {
			allResults = append(allResults, result.items...)
		}
	}

	// æ£€æŸ¥é”™è¯¯
	if len(errors) > 0 {
		return allResults, fmt.Errorf("partial failures: %v", errors)
	}

	return allResults, nil
}

// processSingleGroup å¤„ç†å•ä¸ªåˆ†ç»„
func (c *LLMServiceClient) processSingleGroup(ctx context.Context, prefix string, data []PDFOccupationCode, taskType string) ([]CleanedDataItem, error) {
	// æ„å»ºåˆ†ç»„æ•°æ®çš„JSON
	groupData := map[string]interface{}{
		"category": prefix,
		"items":    data,
	}
	
	jsonData, err := json.MarshalIndent(groupData, "", "  ")
	if err != nil {
		return nil, fmt.Errorf("marshal group data failed: %w", err)
	}

	// æ„å»ºæ¸…æ´—æç¤ºè¯
	prompt := c.buildCleaningPrompt(prefix, string(jsonData))

	// è°ƒç”¨LLMæœåŠ¡
	result, err := c.callLLMServiceWithRetry(ctx, taskType, prompt, c.config.MaxRetries)
	if err != nil {
		return nil, fmt.Errorf("LLM call failed: %w", err)
	}

	// è§£æç»“æœ
	return c.parseCleaningResult(result, prefix)
}

// buildCleaningPrompt æ„å»ºæ•°æ®æ¸…æ´—æç¤ºè¯
func (c *LLMServiceClient) buildCleaningPrompt(prefix string, data string) string {
	return fmt.Sprintf(`ä½ æ˜¯ä¸€åæ•°æ®æ¸…æ´—ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ä»PDFæå–çš„ç¬¬%så¤§ç±»èŒä¸šåˆ†ç±»æ•°æ®ã€‚

æ ¸å¿ƒæ•°æ®ï¼š
%s

æ¸…æ´—è§„åˆ™ï¼š
1. è¯†åˆ«æ‰€æœ‰æœ‰æ•ˆçš„èŒä¸šç¼–ç ï¼ˆæ ¼å¼å¦‚ï¼š%s-01-01-01ï¼‰
2. ä¿®æ­£OCRè¯†åˆ«é”™è¯¯
3. æ ‡å‡†åŒ–èŒä¸šåç§°
4. ä¿æŒåŒä¸€å¤§ç±»å†…çš„ä¸€è‡´æ€§
5. å»é™¤æè¿°æ€§æ–‡å­—å’Œæ— å…³å†…å®¹

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
è¿”å›JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
{
  "code": "èŒä¸šç¼–ç ",
  "name": "èŒä¸šåç§°",
  "confidence": "ç½®ä¿¡åº¦(0-1)",
  "source": "pdf",
  "level": "ç»†ç±»"
}

åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚`, prefix, data, prefix)
}

// parseCleaningResult è§£ææ¸…æ´—ç»“æœ
func (c *LLMServiceClient) parseCleaningResult(result string, prefix string) ([]CleanedDataItem, error) {
	// æ¸…ç†å“åº”ï¼Œæå–JSONéƒ¨åˆ†
	cleanResult := c.extractJSON(result)

	var items []CleanedDataItem
	if err := json.Unmarshal([]byte(cleanResult), &items); err != nil {
		return nil, fmt.Errorf("parse cleaning result failed: %w", err)
	}

	// åå¤„ç†ï¼šè®¾ç½®å¤„ç†æ—¶é—´å’Œæ¥æº
	now := time.Now()
	for i := range items {
		items[i].ProcessedBy = "llm_cleaning"
		items[i].CleanedAt = now
	}

	return items, nil
}

// processSemanticChoicesWithTaskRotation ä½¿ç”¨ä»»åŠ¡ç±»å‹è½®è¯¢å¤„ç†è¯­ä¹‰é€‰æ‹©
func (c *LLMServiceClient) processSemanticChoicesWithTaskRotation(ctx context.Context, choices []SemanticChoice, baseTaskType string) ([]FinalResultItem, error) {
	// å®šä¹‰ä»»åŠ¡ç±»å‹è½®è¯¢æ± 
	taskTypes := []string{
		"semantic_analysis",
		"data_cleaning", // å¤ç”¨æ•°æ®æ¸…æ´—é˜Ÿåˆ—
	}

	type itemResult struct {
		index  int
		result FinalResultItem
		err    error
	}

	resultCh := make(chan itemResult, len(choices))
	var wg sync.WaitGroup

	// ä¸ºæ¯ä¸ªé€‰æ‹©é¡¹å¯åŠ¨goroutineï¼Œè½®è¯¢ä½¿ç”¨ä¸åŒä»»åŠ¡ç±»å‹
	for i, choice := range choices {
		wg.Add(1)
		taskType := taskTypes[i%len(taskTypes)] // è½®è¯¢åˆ†é…ä»»åŠ¡ç±»å‹

		go func(idx int, item SemanticChoice, tType string) {
			defer wg.Done()

			// è·å–å¹¶å‘è®¸å¯
			if err := c.concurrency.AcquirePermit(ctx, tType); err != nil {
				resultCh <- itemResult{index: idx, err: err}
				return
			}
			defer c.concurrency.ReleasePermit(tType)

			// å¤„ç†å•ä¸ªè¯­ä¹‰é€‰æ‹©
			result, err := c.processSingleSemanticChoice(ctx, item, tType)
			resultCh <- itemResult{
				index:  idx,
				result: result,
				err:    err,
			}

			// æ›´æ–°æŒ‡æ ‡
			c.concurrency.UpdateMetrics(tType, TaskMetrics{
				Duration: time.Since(time.Now()),
				Success:  err == nil,
				ErrorType: func() string {
					if err != nil {
						return err.Error()
					}
					return ""
				}(),
			})
		}(i, choice, taskType)
	}

	// ç­‰å¾…æ‰€æœ‰goroutineå®Œæˆ
	go func() {
		wg.Wait()
		close(resultCh)
	}()

	// æ”¶é›†ç»“æœå¹¶ä¿æŒé¡ºåº
	results := make([]FinalResultItem, len(choices))
	errorCount := 0

	for res := range resultCh {
		if res.err != nil {
			errorCount++
			// ä½¿ç”¨é»˜è®¤å€¼
			results[res.index] = c.createDefaultResult(choices[res.index])
		} else {
			results[res.index] = res.result
		}
	}

	// æ£€æŸ¥é”™è¯¯ç‡
	if errorCount > len(choices)/2 {
		return results, fmt.Errorf("too many failures: %d/%d", errorCount, len(choices))
	}

	return results, nil
}

// processSingleSemanticChoice å¤„ç†å•ä¸ªè¯­ä¹‰é€‰æ‹©
func (c *LLMServiceClient) processSingleSemanticChoice(ctx context.Context, choice SemanticChoice, taskType string) (FinalResultItem, error) {
	// æ„å»ºè¯­ä¹‰åˆ†ææç¤ºè¯
	prompt := c.buildSemanticPrompt(choice)

	// è°ƒç”¨LLMæœåŠ¡
	result, err := c.callLLMServiceWithRetry(ctx, taskType, prompt, c.config.MaxRetries)
	if err != nil {
		return FinalResultItem{}, fmt.Errorf("LLM call failed: %w", err)
	}

	// è§£æç»“æœ
	return c.parseSemanticResult(result, choice)
}

// buildSemanticPrompt æ„å»ºè¯­ä¹‰åˆ†ææç¤ºè¯
func (c *LLMServiceClient) buildSemanticPrompt(choice SemanticChoice) string {
	return fmt.Sprintf(`ä½ æ˜¯èŒä¸šåˆ†ç±»ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹èŒä¸šç¼–ç é€‰æ‹©æœ€åˆé€‚çš„åç§°ï¼š

ç¼–ç ï¼š%s
é€‰é¡¹1ï¼š%s
é€‰é¡¹2ï¼š%s
çˆ¶çº§ç±»åˆ«ï¼š%s

é€‰æ‹©è§„åˆ™ï¼š
- åªèƒ½é€‰æ‹©é€‰é¡¹1æˆ–é€‰é¡¹2ï¼Œä¸èƒ½åˆ›é€ æ–°åç§°
- é€‰æ‹©ä¸çˆ¶çº§å±‚æ¬¡è¯­ä¹‰æ›´è¿è´¯çš„åç§°
- ä¼˜å…ˆé€‰æ‹©å®Œæ•´çš„ã€åè¯æ€§çš„èŒä¸šåç§°
- å¦‚æœä¸¤ä¸ªåç§°ç›¸ä¼¼ï¼Œé€‰æ‹©æ›´å®Œæ•´ã€æ›´è§„èŒƒçš„ç‰ˆæœ¬
- æ’é™¤åŒ…å«"æœ¬å°ç±»åŒ…æ‹¬"ã€"è¿›è¡Œ..."ã€"æ‹…ä»»..."ç­‰æè¿°æ€§çŸ­è¯­

è¿”å›JSONæ ¼å¼ï¼š
{
  "code": "ç¼–ç ",
  "name": "é€‰æ‹©åçš„åç§°",
  "parent_name": "çˆ¶çº§ç±»åˆ«åç§°",
  "selected_from": "rule"æˆ–"pdf"
}`, choice.Code, choice.RuleName, choice.PDFName, choice.ParentHierarchy)
}

// parseSemanticResult è§£æè¯­ä¹‰åˆ†æç»“æœ
func (c *LLMServiceClient) parseSemanticResult(result string, choice SemanticChoice) (FinalResultItem, error) {
	// æ¸…ç†å“åº”ï¼Œæå–JSONéƒ¨åˆ†
	cleanResult := c.extractJSON(result)

	var semanticResult map[string]interface{}
	if err := json.Unmarshal([]byte(cleanResult), &semanticResult); err != nil {
		return FinalResultItem{}, fmt.Errorf("parse semantic result failed: %w", err)
	}

	// æ„å»ºæœ€ç»ˆç»“æœ
	finalResult := FinalResultItem{
		Code:        choice.Code,
		Level:       "ç»†ç±»",
		Source:      "llm_semantic",
		ProcessedAt: time.Now(),
	}

	// è§£æåç§°
	if name, ok := semanticResult["name"].(string); ok {
		finalResult.Name = name
	} else {
		finalResult.Name = choice.RuleName // é»˜è®¤å€¼
	}

	// è§£æçˆ¶çº§ç¼–ç 
	if parentCode, ok := semanticResult["parent_code"].(string); ok {
		finalResult.ParentCode = parentCode
	} else {
		finalResult.ParentCode = c.inferParentCode(choice.Code)
	}

	// è§£æå…ƒæ•°æ®
	finalResult.Metadata.ProcessingStage = "semantic_analysis"
	if selectedFrom, ok := semanticResult["selected_from"].(string); ok {
		finalResult.Metadata.SelectedFrom = selectedFrom
		// è®¾ç½®å¤‡é€‰åç§°
		if selectedFrom == "rule" {
			finalResult.Metadata.AlternativeName = choice.PDFName
		} else {
			finalResult.Metadata.AlternativeName = choice.RuleName
		}
	}

	// è®¡ç®—ç½®ä¿¡åº¦
	finalResult.Confidence = c.calculateConfidence(choice, semanticResult)
	finalResult.Metadata.QualityScore = finalResult.Confidence

	return finalResult, nil
}

// createDefaultResult åˆ›å»ºé»˜è®¤ç»“æœ
func (c *LLMServiceClient) createDefaultResult(choice SemanticChoice) FinalResultItem {
	return FinalResultItem{
		Code:        choice.Code,
		Name:        choice.RuleName, // é»˜è®¤ä½¿ç”¨è§„åˆ™åç§°
		Level:       "ç»†ç±»",
		ParentCode:  c.inferParentCode(choice.Code),
		Source:      "default_fallback",
		Confidence:  0.5, // ä¸­ç­‰ç½®ä¿¡åº¦
		ProcessedAt: time.Now(),
		Metadata: struct {
			SelectedFrom    string  `json:"selected_from"`
			AlternativeName string  `json:"alternative_name,omitempty"`
			ProcessingStage string  `json:"processing_stage"`
			QualityScore    float64 `json:"quality_score"`
		}{
			SelectedFrom:    "rule",
			AlternativeName: choice.PDFName,
			ProcessingStage: "fallback",
			QualityScore:    0.5,
		},
	}
}

// calculateConfidence è®¡ç®—ç½®ä¿¡åº¦
func (c *LLMServiceClient) calculateConfidence(choice SemanticChoice, result map[string]interface{}) float64 {
	baseConfidence := 0.8

	// æ ¹æ®è§„åˆ™å’ŒPDFçš„ç½®ä¿¡åº¦è°ƒæ•´
	ruleConf := choice.Confidence.RuleConfidence
	pdfConf := choice.Confidence.PDFConfidence

	if ruleConf > 0 && pdfConf > 0 {
		// ä¸¤ä¸ªæ¥æºéƒ½æœ‰æ•°æ®ï¼Œå–å¹³å‡å¹¶åŠ æƒ
		avgConf := (ruleConf + pdfConf) / 2
		return baseConfidence * avgConf
	} else if ruleConf > 0 {
		// åªæœ‰è§„åˆ™æ•°æ®
		return baseConfidence * ruleConf
	} else if pdfConf > 0 {
		// åªæœ‰PDFæ•°æ®
		return baseConfidence * pdfConf * 0.8 // PDFæ•°æ®æƒé‡ç¨ä½
	}

	return baseConfidence
}

// inferParentCode æ¨æ–­çˆ¶çº§ç¼–ç 
func (c *LLMServiceClient) inferParentCode(code string) string {
	parts := strings.Split(code, "-")
	if len(parts) > 1 {
		return strings.Join(parts[:len(parts)-1], "-")
	}
	return ""
}

// extractJSON ä»å“åº”ä¸­æå–JSONéƒ¨åˆ†
func (c *LLMServiceClient) extractJSON(response string) string {
	response = strings.TrimSpace(response)
	
	// ç§»é™¤markdownæ ‡è®°
	if strings.HasPrefix(response, "```json") {
		response = strings.TrimPrefix(response, "```json")
		response = strings.TrimSuffix(response, "```")
		response = strings.TrimSpace(response)
	} else if strings.HasPrefix(response, "```") {
		response = strings.TrimPrefix(response, "```")
		response = strings.TrimSuffix(response, "```")
		response = strings.TrimSpace(response)
	}

	// æŸ¥æ‰¾JSONæ•°ç»„
	start := strings.Index(response, "[")
	end := strings.LastIndex(response, "]")
	if start != -1 && end != -1 && end > start {
		return response[start : end+1]
	}

	// æŸ¥æ‰¾JSONå¯¹è±¡
	start = strings.Index(response, "{")
	end = strings.LastIndex(response, "}")
	if start != -1 && end != -1 && end > start {
		return response[start : end+1]
	}

	return response
}

// callLLMServiceWithRetry å¸¦é‡è¯•çš„LLMæœåŠ¡è°ƒç”¨
func (c *LLMServiceClient) callLLMServiceWithRetry(ctx context.Context, taskType string, prompt string, maxRetries int) (string, error) {
	var lastErr error

	for i := 0; i < maxRetries; i++ {
		if i > 0 {
			// æŒ‡æ•°é€€é¿
			backoff := time.Duration(i*i) * time.Second
			if backoff > 30*time.Second {
				backoff = 30 * time.Second
			}
			
			select {
			case <-time.After(backoff):
			case <-ctx.Done():
				return "", ctx.Err()
			}
		}

		result, err := c.callLLMServiceAsync(ctx, taskType, prompt)
		if err == nil {
			return result, nil
		}

		lastErr = err
		if ctx.Err() != nil {
			return "", ctx.Err()
		}
	}

	return "", fmt.Errorf("LLM service call failed after %d retries: %w", maxRetries, lastErr)
}

// callLLMServiceAsync å¼‚æ­¥è°ƒç”¨LLMæœåŠ¡
func (c *LLMServiceClient) callLLMServiceAsync(ctx context.Context, taskType string, prompt string) (string, error) {
	fmt.Printf("ğŸŒ [LLMè°ƒç”¨] ä»»åŠ¡ç±»å‹=%s, Prompté•¿åº¦=%d\n", taskType, len(prompt))
	
	// æ„å»ºè¯·æ±‚
	request := map[string]interface{}{
		"type":    taskType,
		"prompt":  prompt,
		"model":   "moonshot-v1-128k",
		"priority": "normal",
	}

	jsonData, err := json.Marshal(request)
	if err != nil {
		return "", fmt.Errorf("marshal request failed: %w", err)
	}

	// è°ƒç”¨LLMæœåŠ¡
	url := fmt.Sprintf("http://%s/api/v1/tasks", c.config.BaseURL)
	req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(jsonData))
	if err != nil {
		return "", fmt.Errorf("create request failed: %w", err)
	}
	req.Header.Set("Content-Type", "application/json")

	resp, err := c.httpClient.Do(req)
	if err != nil {
		fmt.Printf("âŒ [LLMè°ƒç”¨å¤±è´¥] HTTPè¯·æ±‚é”™è¯¯: %v\n", err)
		return "", fmt.Errorf("HTTP request failed: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusAccepted && resp.StatusCode != http.StatusCreated {
		fmt.Printf("âŒ [LLMè°ƒç”¨å¤±è´¥] å“åº”çŠ¶æ€ç : %d\n", resp.StatusCode)
		return "", fmt.Errorf("LLM service returned error %d", resp.StatusCode)
	}

	// è·å–ä»»åŠ¡ID
	var taskResp map[string]interface{}
	if err := json.NewDecoder(resp.Body).Decode(&taskResp); err != nil {
		return "", fmt.Errorf("decode task response failed: %w", err)
	}

	taskID, ok := taskResp["task_id"].(string)
	if !ok {
		fmt.Printf("âŒ [LLMè°ƒç”¨å¤±è´¥] å“åº”ä¸­æ— æ•ˆçš„task_id: %+v\n", taskResp)
		return "", fmt.Errorf("invalid task_id in response")
	}

	fmt.Printf("ğŸ•’ [LLMç­‰å¾…] ä»»åŠ¡ID=%s, ç­‰å¾…ç»“æœ...\n", taskID)
	// ç­‰å¾…ç»“æœ
	return c.waitForLLMResult(ctx, taskID)
}

// waitForLLMResult ç­‰å¾…LLMä»»åŠ¡å®Œæˆ
func (c *LLMServiceClient) waitForLLMResult(ctx context.Context, taskID string) (string, error) {
	ticker := time.NewTicker(2 * time.Second)
	defer ticker.Stop()

	timeout := time.After(5 * time.Minute)

	for {
		select {
		case <-ctx.Done():
			return "", ctx.Err()
		case <-timeout:
			return "", fmt.Errorf("LLM task timeout")
		case <-ticker.C:
			status, err := c.checkLLMTaskStatus(ctx, taskID)
			if err != nil {
				continue // é‡è¯•
			}

			statusStr := status["status"].(string)
			switch statusStr {
			case "completed", "success":
				if result, ok := status["result"].(string); ok {
					fmt.Printf("âœ… [LLMå®Œæˆ] ä»»åŠ¡ID=%s, ç»“æœé•¿åº¦=%d\n", taskID, len(result))
					// éªŒè¯ç»“æœæ˜¯å¦ä¸ºæœ‰æ•ˆçš„JSON
					result = strings.TrimSpace(result)
					if result == "" {
						fmt.Printf("âš ï¸ [LLMç»“æœä¸ºç©º] ä»»åŠ¡ID=%s\n", taskID)
						return "", fmt.Errorf("LLMè¿”å›ç©ºç»“æœ")
					}
					
					// æ‰“å°ç»“æœçš„å‰200å­—ç¬¦ä½œä¸ºç¤ºä¾‹
					if len(result) > 200 {
						fmt.Printf("  ğŸ“ [LLMç»“æœç¤ºä¾‹] %s...\n", result[:200])
					} else {
						fmt.Printf("  ğŸ“ [LLMç»“æœ] %s\n", result)
					}
					
					// æ£€æŸ¥æ˜¯å¦æ˜¯æˆªæ–­çš„ç»“æœ
					if !strings.HasSuffix(result, "}") && !strings.HasSuffix(result, "]") {
						fmt.Printf("âš ï¸ [LLMç»“æœå¯èƒ½è¢«æˆªæ–­] ç»“æœä¸ä»¥}æˆ–]ç»“å°¾\n")
					}
					
					return result, nil
				}
				fmt.Printf("âš ï¸ [LLMç©ºç»“æœ] ä»»åŠ¡ID=%s\n", taskID)
				return "", fmt.Errorf("empty result")
			case "failed", "error":
				errorMsg := "unknown error"
				if errStr, ok := status["error"].(string); ok {
					errorMsg = errStr
				}
				fmt.Printf("âŒ [LLMå¤±è´¥] ä»»åŠ¡ID=%s, é”™è¯¯=%s\n", taskID, errorMsg)
				return "", fmt.Errorf("LLM task failed: %s", errorMsg)
			case "cancelled":
				fmt.Printf("âŒ [LLMå–æ¶ˆ] ä»»åŠ¡ID=%s\n", taskID)
				return "", fmt.Errorf("LLM task cancelled")
			case "processing", "queued":
				// æ­£åœ¨å¤„ç†ï¼Œç»§ç»­ç­‰å¾…
			default:
				fmt.Printf("ğŸ”„ [LLMçŠ¶æ€] ä»»åŠ¡ID=%s, çŠ¶æ€=%s\n", taskID, statusStr)
			}
		}
	}
}

// checkLLMTaskStatus æ£€æŸ¥LLMä»»åŠ¡çŠ¶æ€
func (c *LLMServiceClient) checkLLMTaskStatus(ctx context.Context, taskID string) (map[string]interface{}, error) {
	url := fmt.Sprintf("http://%s/api/v1/tasks/%s", c.config.BaseURL, taskID)
	req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
	if err != nil {
		return nil, err
	}

	resp, err := c.httpClient.Do(req)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("status check failed: %d", resp.StatusCode)
	}

	var status map[string]interface{}
	if err := json.NewDecoder(resp.Body).Decode(&status); err != nil {
		return nil, err
	}

	return status, nil
}