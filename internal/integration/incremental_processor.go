package integration

import (
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"time"

	"github.com/freedkr/moonshot/internal/config"
	"github.com/freedkr/moonshot/internal/database"
	"github.com/freedkr/moonshot/internal/model"
	"github.com/google/uuid"
	"gorm.io/gorm"
)

// IncrementalProcessor å¢é‡æ›´æ–°å¤„ç†å™¨ - å®ç°ç†æƒ³çš„5æ­¥æµç¨‹
type IncrementalProcessor struct {
	config        *config.Config
	httpClient    *http.Client
	db            database.DatabaseInterface
	llmServiceURL string
	pdfServiceURL string
	metrics       MetricsCollector
}

// NewIncrementalProcessor åˆ›å»ºå¢é‡å¤„ç†å™¨
func NewIncrementalProcessor(cfg *config.Config, db database.DatabaseInterface) *IncrementalProcessor {
	return &IncrementalProcessor{
		config: cfg,
		db:     db,
		httpClient: &http.Client{
			Timeout: 120 * time.Second,
		},
		llmServiceURL: getServiceURL(cfg, "llm-service", "8090"),
		pdfServiceURL: getServiceURL(cfg, "pdf-validator", "8000"),
		metrics:       NewMetricsCollector(),
	}
}

// ProcessIncrementalFlow æ‰§è¡Œå¢é‡æ›´æ–°çš„5æ­¥æµç¨‹
func (p *IncrementalProcessor) ProcessIncrementalFlow(ctx context.Context, taskID string, excelPath string, categories []*model.Category) error {
	fmt.Printf("ğŸš€ DEBUG: IncrementalProcessor.ProcessIncrementalFlow å¼€å§‹æ‰§è¡Œ - taskID: %s\n", taskID)
	// æ­¥éª¤1ï¼šå…ˆè§£æexcelä¿å­˜åˆ°è¡¨ä¸­ï¼Œæ­¤æ—¶å¤–éƒ¨æ¥å£å¯ä»¥è°ƒç”¨å¾—åˆ°æ•°æ®æ¸²æŸ“
	err := p.step1SaveExcelData(ctx, taskID, categories)
	if err != nil {
		return fmt.Errorf("æ­¥éª¤1å¤±è´¥: %w", err)
	}

	// æ­¥éª¤2ï¼špdfå¤„ç†å¾—åˆ°çš„ç»“æœè°ƒç”¨llmè¿›è¡Œç¬¬ä¸€æ­¥çš„æ¸…æ´—ï¼Œå¯¹åº”çš„æ•°æ®æ˜¯nameï¼Œcode
	fmt.Printf("ğŸš€ DEBUG: å¼€å§‹æ‰§è¡Œæ­¥éª¤2 - PDFå¤„ç†å’ŒLLMæ¸…æ´— - taskID: %s\n", taskID)
	pdfData, err := p.step2ProcessPDFWithLLM(ctx, taskID)
	if err != nil {
		fmt.Printf("âŒ ERROR: æ­¥éª¤2å¤±è´¥ - taskID: %s, é”™è¯¯: %v\n", taskID, err)
		return fmt.Errorf("æ­¥éª¤2å¤±è´¥: %w", err)
	}
	fmt.Printf("âœ… DEBUG: æ­¥éª¤2å®Œæˆ - taskID: %s, PDFæ•°æ®æ¡æ•°: %d\n", taskID, len(pdfData))

	// æ­¥éª¤3ï¼šå°†excelä¸pdfçš„æ•°æ®é€šè¿‡codeæˆ–è€…nameè¿›è¡Œä¸¤éƒ¨åˆ†çš„åˆå¹¶ï¼ŒåŒºåˆ†excelå’Œpdf
	fmt.Printf("ğŸš€ DEBUG: å¼€å§‹æ‰§è¡Œæ­¥éª¤3 - åˆå¹¶Excelå’ŒPDFæ•°æ® - taskID: %s\n", taskID)
	err = p.step3MergeExcelAndPDFData(ctx, taskID, pdfData)
	if err != nil {
		fmt.Printf("âŒ ERROR: æ­¥éª¤3å¤±è´¥ - taskID: %s, é”™è¯¯: %v\n", taskID, err)
		return fmt.Errorf("æ­¥éª¤3å¤±è´¥: %w", err)
	}
	fmt.Printf("âœ… DEBUG: æ­¥éª¤3å®Œæˆ - taskID: %s\n", taskID)

	// æ­¥éª¤4ï¼šç¬¬äºŒæ¬¡è°ƒç”¨llmï¼Œé€šè¿‡3æ­¥éª¤å¾—åˆ°æ›´ä¸°å¯Œçš„æ•°æ®æŠ•å–‚ç»™llmè¿›è¡Œç­›é€‰
	fmt.Printf("ğŸš€ DEBUG: å¼€å§‹æ‰§è¡Œæ­¥éª¤4 - ç¬¬äºŒæ¬¡LLMå¢å¼º - taskID: %s\n", taskID)
	enhancedData, err := p.step4EnhanceWithSecondLLM(ctx, taskID)
	if err != nil {
		fmt.Printf("âŒ ERROR: æ­¥éª¤4å¤±è´¥ - taskID: %s, é”™è¯¯: %v\n", taskID, err)
		return fmt.Errorf("æ­¥éª¤4å¤±è´¥: %w", err)
	}
	fmt.Printf("âœ… DEBUG: æ­¥éª¤4å®Œæˆ - taskID: %s, å¢å¼ºæ•°æ®æ¡æ•°: %d\n", taskID, len(enhancedData))

	// æ­¥éª¤5ï¼šæœ€ç»ˆç­›é€‰åçš„ç»“æœæ›´æ–°ä¼šåˆ†ç±»è¡¨ä¸­
	fmt.Printf("ğŸš€ DEBUG: å¼€å§‹æ‰§è¡Œæ­¥éª¤5 - æ›´æ–°æœ€ç»ˆç»“æœ - taskID: %s\n", taskID)
	err = p.step5UpdateFinalResults(ctx, taskID, enhancedData)
	if err != nil {
		fmt.Printf("âŒ ERROR: æ­¥éª¤5å¤±è´¥ - taskID: %s, é”™è¯¯: %v\n", taskID, err)
		return fmt.Errorf("æ­¥éª¤5å¤±è´¥: %w", err)
	}
	fmt.Printf("âœ… DEBUG: æ­¥éª¤5å®Œæˆ - taskID: %s\n", taskID)
	fmt.Printf("ğŸ‰ DEBUG: å¢é‡å¤„ç†æµç¨‹å…¨éƒ¨å®Œæˆ - taskID: %s\n", taskID)

	return nil
}

// step1SaveExcelData æ­¥éª¤1ï¼šä¿å­˜Excelè§£ææ•°æ®
func (p *IncrementalProcessor) step1SaveExcelData(ctx context.Context, taskID string, categories []*model.Category) error {
	p.metrics.RecordProcessingDuration("excel_parsing", time.Since(time.Now()))

	// ç”Ÿæˆæ–°çš„æ‰¹æ¬¡ID
	batchID := uuid.New().String()
	currentTime := time.Now()

	// è½¬æ¢ä¸ºæ•°æ®åº“æ ¼å¼ï¼ŒåŒ…å«ç‰ˆæœ¬åŒ–å­—æ®µ
	var dbCategories []*database.Category
	for _, cat := range categories {
		dbCat := &database.Category{
			TaskID:          taskID,
			Code:            cat.Code,
			Name:            cat.Name,
			Level:           cat.Level,
			ParentCode:      cat.GetParentCode(),
			Status:          database.StatusExcelParsed,
			DataSource:      database.DataSourceExcel,
			UploadBatchID:   batchID,
			UploadTimestamp: currentTime,
			IsCurrent:       true, // æ–°æ’å…¥çš„è®°å½•è®¾ä¸ºå½“å‰ç‰ˆæœ¬
		}
		dbCategories = append(dbCategories, dbCat)
	}

	// ä½¿ç”¨ç‰ˆæœ¬åŒ–é€»è¾‘ï¼šå…ˆæ ‡è®°æ—§ç‰ˆæœ¬ï¼Œå†æ’å…¥æ–°ç‰ˆæœ¬
	pgDB, ok := p.db.(*database.PostgreSQLDB)
	if !ok {
		return fmt.Errorf("æ•°æ®åº“ç±»å‹é”™è¯¯")
	}

	// æ·»åŠ è°ƒè¯•æ—¥å¿—
	fmt.Printf("DEBUG: å‡†å¤‡å¤„ç†taskID=%sçš„æ•°æ®ï¼Œå…±%dæ¡è®°å½•ï¼ŒbatchID=%s\n", taskID, len(dbCategories), batchID)

	err := pgDB.GetDB().WithContext(ctx).Transaction(func(tx *gorm.DB) error {
		// æ£€æŸ¥æ˜¯å¦å­˜åœ¨å½“å‰ç‰ˆæœ¬è®°å½•
		var existingCount int64
		if err := tx.Model(&database.Category{}).Where("task_id = ? AND is_current = true", taskID).Count(&existingCount).Error; err != nil {
			return fmt.Errorf("æ£€æŸ¥å·²å­˜åœ¨æ•°æ®å¤±è´¥: %w", err)
		}
		fmt.Printf("DEBUG: taskID=%s å·²å­˜åœ¨å½“å‰ç‰ˆæœ¬è®°å½•%dæ¡\n", taskID, existingCount)

		// å°†ç°æœ‰çš„å½“å‰ç‰ˆæœ¬æ ‡è®°ä¸ºå†å²ç‰ˆæœ¬
		if existingCount > 0 {
			result := tx.Model(&database.Category{}).
				Where("task_id = ? AND is_current = true", taskID).
				Update("is_current", false)
			if result.Error != nil {
				return fmt.Errorf("æ ‡è®°å†å²ç‰ˆæœ¬å¤±è´¥: %w", result.Error)
			}
			fmt.Printf("DEBUG: æ ‡è®°äº†%dæ¡è®°å½•ä¸ºå†å²ç‰ˆæœ¬\n", result.RowsAffected)
		}

		// æ‰¹é‡æ’å…¥æ–°çš„å½“å‰ç‰ˆæœ¬æ•°æ®
		if err := tx.CreateInBatches(dbCategories, 100).Error; err != nil {
			return fmt.Errorf("æ‰¹é‡æ’å…¥æ•°æ®å¤±è´¥: %w", err)
		}
		fmt.Printf("DEBUG: æˆåŠŸæ’å…¥%dæ¡æ–°çš„å½“å‰ç‰ˆæœ¬è®°å½•ï¼ŒbatchID=%s\n", len(dbCategories), batchID)

		return nil
	})

	if err != nil {
		p.metrics.RecordError("excel_parsing", err)
		return fmt.Errorf("ä¿å­˜Excelæ•°æ®å¤±è´¥: %w", err)
	}

	p.metrics.RecordSuccess("excel_parsing")
	fmt.Printf("DEBUG: Excelæ•°æ®ç‰ˆæœ¬åŒ–ä¿å­˜å®Œæˆ - taskID=%s, batchID=%s\n", taskID, batchID)
	return nil
}

// step2ProcessPDFWithLLM æ­¥éª¤2ï¼šPDFå¤„ç†å¹¶è°ƒç”¨LLMæ¸…æ´—
func (p *IncrementalProcessor) step2ProcessPDFWithLLM(ctx context.Context, taskID string) ([]map[string]interface{}, error) {
	startTime := time.Now()
	defer func() {
		p.metrics.RecordProcessingDuration("pdf_llm_cleaning", time.Since(startTime))
	}()

	// è°ƒç”¨PDFéªŒè¯æœåŠ¡ (å¤ç”¨ç°æœ‰é€»è¾‘)
	pdfResult, err := p.callPDFValidator(ctx, taskID)
	if err != nil {
		p.metrics.RecordError("pdf_llm_cleaning", err)
		return nil, fmt.Errorf("PDFéªŒè¯å¤±è´¥: %w", err)
	}

	// ğŸ“Š DEBUG: PDFéªŒè¯å®Œæˆï¼Œè®°å½•åŸå§‹æ•°æ®å¤§å°
	fmt.Printf("ğŸ“Š DEBUG: PDFéªŒè¯å®Œæˆï¼ŒåŸå§‹æ•°æ®å¤§å°: %v\n", len(fmt.Sprintf("%+v", pdfResult)))

	// ç¬¬ä¸€è½®LLMåˆ†æ - æ¸…æ´—PDFç»“æœ
	cleanedPDFData, err := p.firstLLMAnalysis(ctx, pdfResult)
	if err != nil {
		p.metrics.RecordError("pdf_llm_cleaning", err)
		return nil, fmt.Errorf("ç¬¬ä¸€è½®LLMåˆ†æå¤±è´¥: %w", err)
	}

	fmt.Printf("ğŸ¯ DEBUG: ç¬¬ä¸€è½®LLMåˆ†æå®Œæˆï¼Œæ¸…æ´—åæ•°æ®æ¡æ•°: %d\n", len(cleanedPDFData))

	p.metrics.RecordSuccess("pdf_llm_cleaning")
	return cleanedPDFData, nil
}

// step3MergeExcelAndPDFData æ­¥éª¤3ï¼šèåˆExcelå’ŒPDFæ•°æ®
func (p *IncrementalProcessor) step3MergeExcelAndPDFData(ctx context.Context, taskID string, pdfData []map[string]interface{}) error {
	startTime := time.Now()
	defer func() {
		p.metrics.RecordProcessingDuration("data_merging", time.Since(startTime))
	}()

	fmt.Printf("ğŸ“Š [Step3-å¼€å§‹] taskID=%s, PDFæ•°æ®æ¡æ•°=%d\n", taskID, len(pdfData))

	pgDB, ok := p.db.(*database.PostgreSQLDB)
	if !ok {
		return fmt.Errorf("æ•°æ®åº“ç±»å‹é”™è¯¯")
	}

	// åˆ›å»ºPDFæ•°æ®çš„Codeæ˜ å°„
	pdfCodeMap := make(map[string]map[string]interface{})
	pdfNameMap := make(map[string]map[string]interface{})

	for _, item := range pdfData {
		code, hasCode := item["code"].(string)
		name, hasName := item["name"].(string)

		if hasCode && code != "" {
			pdfCodeMap[code] = item
			fmt.Printf("  ğŸ“ [Step3-PDFæ˜ å°„] Codeæ˜ å°„: %s -> %v\n", code, item["name"])
		}
		if hasName && name != "" {
			pdfNameMap[name] = item
		}
	}
	fmt.Printf("ğŸ“Š [Step3-æ˜ å°„å®Œæˆ] Codeæ˜ å°„æ•°=%d, Nameæ˜ å°„æ•°=%d\n", len(pdfCodeMap), len(pdfNameMap))

	// æ‰¹é‡æ›´æ–°æ•°æ®åº“ä¸­çš„è®°å½•
	var updates []database.CategoryUpdate

	// è·å–ç°æœ‰çš„Excelæ•°æ®
	var excelCategories []database.Category
	fmt.Printf("ğŸ” [Step3-æŸ¥è¯¢] æ­£åœ¨æŸ¥è¯¢ task_id=%s AND status=%s çš„è®°å½•...\n", taskID, database.StatusExcelParsed)
	err := pgDB.GetDB().WithContext(ctx).Where("task_id = ? AND status = ?",
		taskID, database.StatusExcelParsed).Find(&excelCategories).Error
	if err != nil {
		p.metrics.RecordError("data_merging", err)
		return fmt.Errorf("è·å–Excelæ•°æ®å¤±è´¥: %w", err)
	}
	fmt.Printf("âœ… [Step3-æŸ¥è¯¢ç»“æœ] æ‰¾åˆ° %d æ¡Excelæ•°æ®è®°å½•\n", len(excelCategories))

	for i, cat := range excelCategories {
		var pdfInfo map[string]interface{}
		var found bool
		var matchType string

		// ä¼˜å…ˆæŒ‰CodeåŒ¹é…
		if pdfInfo, found = pdfCodeMap[cat.Code]; found {
			matchType = "CodeåŒ¹é…"
		} else if pdfInfo, found = pdfNameMap[cat.Name]; found {
			// å¤‡é€‰æŒ‰NameåŒ¹é…
			matchType = "NameåŒ¹é…"
		}

		if found {
			fmt.Printf("  âœ… [Step3-åŒ¹é…æˆåŠŸ] [%d/%d] Code=%s, Name=%s, åŒ¹é…æ–¹å¼=%s\n",
				i+1, len(excelCategories), cat.Code, cat.Name, matchType)
			// åºåˆ—åŒ–PDFä¿¡æ¯
			pdfInfoJSON, _ := json.Marshal(pdfInfo)

			updates = append(updates, database.CategoryUpdate{
				Code: cat.Code,
				Updates: map[string]interface{}{
					"status":      database.StatusPDFMerged,
					"data_source": database.DataSourceMerged,
					"pdf_info":    string(pdfInfoJSON),
				},
			})
		} else {
			if i < 5 { // åªæ‰“å°å‰5ä¸ªæœªåŒ¹é…çš„è®°å½•
				fmt.Printf("  âŒ [Step3-æœªåŒ¹é…] [%d/%d] Code=%s, Name=%s\n",
					i+1, len(excelCategories), cat.Code, cat.Name)
			}
		}
	}
	fmt.Printf("ğŸ“Š [Step3-åŒ¹é…ç»Ÿè®¡] æ€»è®°å½•=%d, æˆåŠŸåŒ¹é…=%d, æœªåŒ¹é…=%d\n",
		len(excelCategories), len(updates), len(excelCategories)-len(updates))

	// æ‰§è¡Œæ‰¹é‡æ›´æ–°
	if len(updates) > 0 {
		fmt.Printf("ğŸ”„ [Step3-æ›´æ–°] å‡†å¤‡æ‰¹é‡æ›´æ–° %d æ¡è®°å½•...\n", len(updates))
		err = p.batchUpdateCategoriesByCode(ctx, taskID, updates)
		if err != nil {
			fmt.Printf("âŒ [Step3-æ›´æ–°å¤±è´¥] é”™è¯¯: %v\n", err)
			p.metrics.RecordError("data_merging", err)
			return fmt.Errorf("æ‰¹é‡æ›´æ–°å¤±è´¥: %w", err)
		}
		fmt.Printf("âœ… [Step3-æ›´æ–°æˆåŠŸ] å·²æ›´æ–° %d æ¡è®°å½•çŠ¶æ€ä¸º %s\n", len(updates), database.StatusPDFMerged)
	} else {
		fmt.Printf("âš ï¸ [Step3-æ— æ›´æ–°] æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è®°å½•éœ€è¦æ›´æ–°\n")
	}

	p.metrics.RecordSuccess("data_merging")
	fmt.Printf("âœ… [Step3-å®Œæˆ] æ•°æ®èåˆæ­¥éª¤å®Œæˆ\n")
	return nil
}

// step4EnhanceWithSecondLLM æ­¥éª¤4ï¼šç¬¬äºŒè½®LLMå¢å¼º
func (p *IncrementalProcessor) step4EnhanceWithSecondLLM(ctx context.Context, taskID string) ([]map[string]interface{}, error) {
	startTime := time.Now()
	defer func() {
		p.metrics.RecordProcessingDuration("llm_enhancement", time.Since(startTime))
	}()

	fmt.Printf("\nğŸš€ [Step4-å¼€å§‹] ç¬¬äºŒè½®LLMå¢å¼º - taskID=%s\n", taskID)

	// è·å–å·²èåˆçš„æ•°æ®
	pgDB, ok := p.db.(*database.PostgreSQLDB)
	if !ok {
		return nil, fmt.Errorf("æ•°æ®åº“ç±»å‹é”™è¯¯")
	}

	// å…ˆæŸ¥è¯¢æ‰€æœ‰çŠ¶æ€ï¼Œäº†è§£æ•°æ®åˆ†å¸ƒ
	var statusCount []struct {
		Status string
		Count  int64
	}
	pgDB.GetDB().Model(&database.Category{}).
		Select("status, count(*) as count").
		Where("task_id = ?", taskID).
		Group("status").
		Scan(&statusCount)

	fmt.Printf("ğŸ“Š [Step4-çŠ¶æ€åˆ†å¸ƒ] taskID=%s çš„æ•°æ®çŠ¶æ€åˆ†å¸ƒ:\n", taskID)
	for _, sc := range statusCount {
		fmt.Printf("  - %s: %d æ¡\n", sc.Status, sc.Count)
	}

	var mergedCategories []database.Category
	fmt.Printf("ğŸ” [Step4-æŸ¥è¯¢] æ­£åœ¨æŸ¥è¯¢ task_id=%s AND status=%s çš„è®°å½•...\n", taskID, database.StatusPDFMerged)
	err := pgDB.GetDB().WithContext(ctx).Where("task_id = ? AND status = ?",
		taskID, database.StatusPDFMerged).Find(&mergedCategories).Error
	if err != nil {
		fmt.Printf("âŒ [Step4-æŸ¥è¯¢å¤±è´¥] é”™è¯¯: %v\n", err)
		p.metrics.RecordError("llm_enhancement", err)
		return nil, fmt.Errorf("è·å–èåˆæ•°æ®å¤±è´¥: %w", err)
	}

	fmt.Printf("âœ… [Step4-æŸ¥è¯¢ç»“æœ] è·å–åˆ°èåˆæ•°æ® %d æ¡\n", len(mergedCategories))

	// å¦‚æœæ²¡æœ‰èåˆæ•°æ®ï¼Œå°è¯•ä½¿ç”¨æ‰€æœ‰Excelæ•°æ®
	if len(mergedCategories) == 0 {
		fmt.Printf("âš ï¸ [Step4-é™çº§å¤„ç†] æ²¡æœ‰æ‰¾åˆ°pdf_mergedçŠ¶æ€çš„æ•°æ®ï¼Œå°è¯•ä½¿ç”¨excel_parsedçŠ¶æ€çš„æ•°æ®...\n")
		err = pgDB.GetDB().WithContext(ctx).Where("task_id = ? AND status = ?",
			taskID, database.StatusExcelParsed).Find(&mergedCategories).Error
		if err != nil {
			fmt.Printf("âŒ [Step4-é™çº§å¤±è´¥] è·å–Excelæ•°æ®å¤±è´¥: %v\n", err)
			return nil, fmt.Errorf("è·å–Excelæ•°æ®å¤±è´¥: %w", err)
		}
		fmt.Printf("âœ… [Step4-é™çº§æˆåŠŸ] è·å–åˆ°Excelæ•°æ® %d æ¡\n", len(mergedCategories))
	}

	// å‡†å¤‡ä¸°å¯Œæ•°æ®ä¾›LLMåˆ†æ
	enrichedChoices := p.prepareEnrichedData(mergedCategories)
	fmt.Printf("ğŸ”„ [Step4-å‡†å¤‡æ•°æ®] å‡†å¤‡ç¬¬äºŒè½®LLMåˆ†æï¼Œå€™é€‰æ•°æ®: %d æ¡\n", len(enrichedChoices))

	// æ‰¹é‡å¤„ç†ï¼šæ¯æ‰¹10æ¡ï¼Œå¤„ç†å®Œç«‹å³æ›´æ–°æ•°æ®åº“
	batchSize := 10
	totalProcessed := 0
	var allResults []map[string]interface{}

	for i := 0; i < len(enrichedChoices); i += batchSize {
		end := i + batchSize
		if end > len(enrichedChoices) {
			end = len(enrichedChoices)
		}

		batch := enrichedChoices[i:end]
		batchNum := (i / batchSize) + 1
		fmt.Printf("\nğŸ“¦ [Step4-æ‰¹æ¬¡%d] å¤„ç†ç¬¬ %d-%d æ¡æ•°æ®ï¼ˆå…±%dæ¡ï¼‰\n", batchNum, i+1, end, len(enrichedChoices))

		// æ‰“å°å½“å‰æ‰¹æ¬¡çš„å‰3ä¸ªå€™é€‰æ•°æ®
		for j, choice := range batch {
			if j >= 3 {
				break
			}
			fmt.Printf("  ğŸ“ [æ‰¹æ¬¡%d-æ•°æ®%d] Code=%s, RuleName=%s, PdfName=%s\n",
				batchNum, j+1, choice.Code, choice.RuleName, choice.PdfName)
		}

		// ç¬¬äºŒè½®LLMåˆ†æ - å¤„ç†å½“å‰æ‰¹æ¬¡
		fmt.Printf("ğŸ¤– [Step4-æ‰¹æ¬¡%d-LLM] å¼€å§‹LLMåˆ†æ...\n", batchNum)
		batchResult, err := p.secondLLMAnalysis(ctx, batch)
		if err != nil {
			fmt.Printf("âŒ [Step4-æ‰¹æ¬¡%d-å¤±è´¥] LLMåˆ†æå¤±è´¥: %vï¼Œè·³è¿‡æœ¬æ‰¹æ¬¡\n", batchNum, err)
			p.metrics.RecordError("llm_enhancement_batch", err)
			continue // è·³è¿‡å¤±è´¥çš„æ‰¹æ¬¡ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹
		}

		fmt.Printf("âœ… [Step4-æ‰¹æ¬¡%d-æˆåŠŸ] LLMåˆ†æå®Œæˆï¼Œè¿”å› %d æ¡ç»“æœ\n", batchNum, len(batchResult))

		// ç«‹å³æ›´æ–°è¿™æ‰¹æ•°æ®åˆ°æ•°æ®åº“
		if len(batchResult) > 0 {
			fmt.Printf("ğŸ’¾ [Step4-æ‰¹æ¬¡%d-æ›´æ–°] ç«‹å³æ›´æ–°æ•°æ®åº“...\n", batchNum)
			if err := p.updateBatchLLMResults(ctx, taskID, batchResult); err != nil {
				fmt.Printf("âŒ [Step4-æ‰¹æ¬¡%d-æ›´æ–°å¤±è´¥] æ•°æ®åº“æ›´æ–°å¤±è´¥: %v\n", batchNum, err)
			} else {
				fmt.Printf("âœ… [Step4-æ‰¹æ¬¡%d-æ›´æ–°æˆåŠŸ] å·²æ›´æ–° %d æ¡è®°å½•\n", batchNum, len(batchResult))
				totalProcessed += len(batchResult)
			}
		}

		// æ”¶é›†æ‰€æœ‰ç»“æœï¼ˆç”¨äºè¿”å›ï¼‰
		allResults = append(allResults, batchResult...)

		// æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¿‡åº¦å‹åŠ›
		if i+batchSize < len(enrichedChoices) {
			fmt.Printf("â±ï¸ [Step4-æ‰¹æ¬¡%d] ç­‰å¾…1ç§’åå¤„ç†ä¸‹ä¸€æ‰¹...\n", batchNum)
			time.Sleep(1 * time.Second)
		}
	}

	fmt.Printf("\nâœ… [Step4-å®Œæˆ] æ‰¹é‡LLMåˆ†æå®Œæˆï¼Œæ€»è®¡å¤„ç†å¹¶æ›´æ–°: %d æ¡\n", totalProcessed)
	p.metrics.RecordSuccess("llm_enhancement")
	return allResults, nil
}

// step5UpdateFinalResults æ­¥éª¤5ï¼šæœ€ç»ˆçŠ¶æ€æ£€æŸ¥ï¼ˆæ•°æ®å·²åœ¨step4æ‰¹é‡æ›´æ–°ï¼‰
func (p *IncrementalProcessor) step5UpdateFinalResults(ctx context.Context, taskID string, enhancedData []map[string]interface{}) error {
	startTime := time.Now()
	defer func() {
		p.metrics.RecordProcessingDuration("final_update", time.Since(startTime))
	}()

	fmt.Printf("\nğŸš€ [Step5-å¼€å§‹] æœ€ç»ˆçŠ¶æ€æ£€æŸ¥ - taskID=%s\n", taskID)

	// ç”±äºæ•°æ®å·²åœ¨step4ä¸­æ‰¹é‡æ›´æ–°ï¼Œè¿™é‡ŒåªåšçŠ¶æ€æ£€æŸ¥
	pgDB, ok := p.db.(*database.PostgreSQLDB)
	if !ok {
		return fmt.Errorf("æ•°æ®åº“ç±»å‹é”™è¯¯")
	}

	// ç»Ÿè®¡æ›´æ–°ç»“æœ
	var statusStats []struct {
		Status string
		Count  int64
	}
	err := pgDB.GetDB().Model(&database.Category{}).
		Select("status, count(*) as count").
		Where("task_id = ?", taskID).
		Group("status").
		Scan(&statusStats).Error

	if err != nil {
		fmt.Printf("âŒ [Step5-ç»Ÿè®¡å¤±è´¥] é”™è¯¯: %v\n", err)
		return fmt.Errorf("ç»Ÿè®¡çŠ¶æ€å¤±è´¥: %w", err)
	}

	fmt.Printf("ğŸ“Š [Step5-æœ€ç»ˆç»Ÿè®¡] ä»»åŠ¡ %s çš„æœ€ç»ˆæ•°æ®çŠ¶æ€:\n", taskID)
	for _, stat := range statusStats {
		fmt.Printf("  - %s: %d æ¡\n", stat.Status, stat.Count)
	}

	// æ£€æŸ¥llm_enhancementså­—æ®µæ˜¯å¦å·²å¡«å……
	var enhancedCount int64
	pgDB.GetDB().Model(&database.Category{}).
		Where("task_id = ? AND llm_enhancements IS NOT NULL AND llm_enhancements != ''", taskID).
		Count(&enhancedCount)

	fmt.Printf("ğŸ“Š [Step5-LLMå¢å¼ºç»Ÿè®¡] LLMå¢å¼ºå­—æ®µå·²å¡«å……: %d æ¡\n", enhancedCount)

	// å¦‚æœæœ‰æœªå¤„ç†çš„æ•°æ®ï¼Œå°è¯•è¡¥å……å¤„ç†ï¼ˆå®¹é”™æœºåˆ¶ï¼‰
	if len(enhancedData) > int(enhancedCount) {
		fmt.Printf("âš ï¸ [Step5-è¡¥å……å¤„ç†] æ£€æµ‹åˆ° %d æ¡æ•°æ®å¯èƒ½æœªæ›´æ–°ï¼Œå°è¯•è¡¥å……æ›´æ–°...\n",
			len(enhancedData)-int(enhancedCount))

		// åªæ›´æ–°é‚£äº›llm_enhancementsä¸ºç©ºçš„è®°å½•
		var updates []database.CategoryUpdate
		for _, item := range enhancedData {
			code, ok := item["code"].(string)
			if !ok || code == "" {
				continue
			}

			// æ£€æŸ¥è¯¥è®°å½•æ˜¯å¦å·²æœ‰llm_enhancements
			var count int64
			pgDB.GetDB().Model(&database.Category{}).
				Where("task_id = ? AND code = ? AND (llm_enhancements IS NULL OR llm_enhancements = '')",
					taskID, code).
				Count(&count)

			if count > 0 {
				llmInfoJSON, _ := json.Marshal(item)
				updates = append(updates, database.CategoryUpdate{
					Code: code,
					Updates: map[string]interface{}{
						"status":           database.StatusCompleted,
						"llm_enhancements": string(llmInfoJSON),
						"name":             item["name"],
					},
				})
			}
		}

		if len(updates) > 0 {
			fmt.Printf("ğŸ”„ [Step5-è¡¥å……æ›´æ–°] æ›´æ–° %d æ¡é—æ¼çš„è®°å½•...\n", len(updates))
			if err := p.batchUpdateCategoriesByCode(ctx, taskID, updates); err != nil {
				fmt.Printf("âŒ [Step5-è¡¥å……å¤±è´¥] é”™è¯¯: %v\n", err)
			} else {
				fmt.Printf("âœ… [Step5-è¡¥å……æˆåŠŸ] å·²è¡¥å……æ›´æ–° %d æ¡è®°å½•\n", len(updates))
			}
		}
	}

	p.metrics.RecordSuccess("final_update")
	fmt.Printf("âœ… [Step5-å®Œæˆ] æœ€ç»ˆæ£€æŸ¥å®Œæˆï¼Œå…± %d æ¡è®°å½•å·²å®ŒæˆLLMå¢å¼º\n\n", enhancedCount)
	return nil
}

// è¾…åŠ©æ–¹æ³• - å¤ç”¨ç°æœ‰é€»è¾‘
func (p *IncrementalProcessor) callPDFValidator(ctx context.Context, taskID string) (map[string]interface{}, error) {
	// å¤ç”¨ç°æœ‰çš„PDFLLMProcessorçš„callPDFValidatoræ–¹æ³•
	processor := NewPDFLLMProcessor(p.config, p.db)
	return processor.callPDFValidator(ctx, taskID, "")
}

func (p *IncrementalProcessor) firstLLMAnalysis(ctx context.Context, pdfResult map[string]interface{}) ([]map[string]interface{}, error) {
	// å¤ç”¨ç°æœ‰çš„PDFLLMProcessorçš„firstLLMAnalysisæ–¹æ³•
	processor := NewPDFLLMProcessor(p.config, p.db)
	return processor.firstLLMAnalysis(ctx, pdfResult)
}

func (p *IncrementalProcessor) secondLLMAnalysis(ctx context.Context, choices []SemanticChoiceItem) ([]map[string]interface{}, error) {
	// å¤ç”¨ç°æœ‰çš„PDFLLMProcessorçš„SecondLLMAnalysisæ–¹æ³•
	processor := NewPDFLLMProcessor(p.config, p.db)
	return processor.SecondLLMAnalysis(ctx, choices)
}

func (p *IncrementalProcessor) prepareEnrichedData(categories []database.Category) []SemanticChoiceItem {
	var choices []SemanticChoiceItem

	for _, cat := range categories {
		choice := SemanticChoiceItem{
			Code:     cat.Code,
			RuleName: cat.Name, // Excelæ•°æ®ä½œä¸ºè§„åˆ™åç§°
		}

		// ä»PDFä¿¡æ¯ä¸­æå–åç§°
		if cat.PDFInfo != "" {
			var pdfInfo map[string]interface{}
			if err := json.Unmarshal([]byte(cat.PDFInfo), &pdfInfo); err == nil {
				if pdfName, ok := pdfInfo["name"].(string); ok {
					choice.PdfName = pdfName
				}
			}
		}

		// è®¾ç½®çˆ¶å±‚çº§ä¿¡æ¯
		choice.ParentHierarchy = cat.ParentCode

		choices = append(choices, choice)
	}

	return choices
}

func (p *IncrementalProcessor) batchUpdateCategoriesByCode(ctx context.Context, taskID string, updates []database.CategoryUpdate) error {
	pgDB, ok := p.db.(*database.PostgreSQLDB)
	if !ok {
		return fmt.Errorf("æ•°æ®åº“ç±»å‹é”™è¯¯")
	}

	fmt.Printf("  ğŸ”„ [æ‰¹é‡æ›´æ–°-å¼€å§‹] å‡†å¤‡æ›´æ–° %d æ¡è®°å½•\n", len(updates))

	// ä½¿ç”¨äº‹åŠ¡æ‰¹é‡æ›´æ–°
	tx := pgDB.GetDB().Begin()
	defer tx.Rollback()

	successCount := 0
	for i, update := range updates {
		result := tx.WithContext(ctx).Model(&database.Category{}).
			Where("task_id = ? AND code = ?", taskID, update.Code).
			Updates(update.Updates)

		if result.Error != nil {
			fmt.Printf("    âŒ [æ›´æ–°å¤±è´¥] Code=%s, é”™è¯¯=%v\n", update.Code, result.Error)
			return fmt.Errorf("æ›´æ–°Code %s å¤±è´¥: %w", update.Code, result.Error)
		}

		if result.RowsAffected > 0 {
			successCount++
			if i < 3 { // æ‰“å°å‰3æ¡æˆåŠŸçš„æ›´æ–°
				fmt.Printf("    âœ… [æ›´æ–°æˆåŠŸ%d] Code=%s, å½±å“è¡Œæ•°=%d\n", i+1, update.Code, result.RowsAffected)
			}
		} else {
			fmt.Printf("    âš ï¸ [æœªæ‰¾åˆ°è®°å½•] Code=%s\n", update.Code)
		}
	}

	fmt.Printf("  ğŸ“Š [æ‰¹é‡æ›´æ–°-ç»Ÿè®¡] æˆåŠŸæ›´æ–°=%d/%d\n", successCount, len(updates))

	if err := tx.Commit().Error; err != nil {
		fmt.Printf("  âŒ [äº‹åŠ¡æäº¤å¤±è´¥] é”™è¯¯=%v\n", err)
		return err
	}
	fmt.Printf("  âœ… [æ‰¹é‡æ›´æ–°-å®Œæˆ] äº‹åŠ¡æäº¤æˆåŠŸ\n")
	return nil
}

// updateBatchLLMResults æ‰¹é‡æ›´æ–°LLMåˆ†æç»“æœåˆ°æ•°æ®åº“
func (p *IncrementalProcessor) updateBatchLLMResults(ctx context.Context, taskID string, results []map[string]interface{}) error {
	var updates []database.CategoryUpdate

	for _, item := range results {
		code, ok := item["code"].(string)
		if !ok || code == "" {
			continue
		}

		// åºåˆ—åŒ–LLMå¢å¼ºä¿¡æ¯
		llmInfoJSON, _ := json.Marshal(item)

		updates = append(updates, database.CategoryUpdate{
			Code: code,
			Updates: map[string]interface{}{
				"status":           database.StatusCompleted,
				"llm_enhancements": string(llmInfoJSON),
				"name":             item["name"], // å¦‚æœLLMä¼˜åŒ–äº†nameï¼Œä¹Ÿæ›´æ–°
			},
		})
	}

	if len(updates) == 0 {
		return nil
	}

	// ä½¿ç”¨ç°æœ‰çš„æ‰¹é‡æ›´æ–°æ–¹æ³•
	return p.batchUpdateCategoriesByCode(ctx, taskID, updates)
}

// GetMetrics è·å–å¤„ç†æŒ‡æ ‡
func (p *IncrementalProcessor) GetMetrics() ProcessingMetrics {
	return p.metrics.GetMetrics()
}
